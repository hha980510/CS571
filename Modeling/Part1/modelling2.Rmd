---
title: "Modeling"
author: "Team Irma, Omoniyi, Parvathi and Hyunsung"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(lubridate)
library(caret)
library(TTR)
library(Metrics)
library(zoo)
library(randomForest)
library(xgboost)
library(e1071)
library(tseries)
``` 

# Modeling

### Load & Prepare Data
```{r}
df <- read_csv("full_cleaned_dataset.csv") %>%
  mutate(date = as.Date(date)) %>%
  arrange(date) %>%
  mutate(
    lag_close = lag(close),
    log_return = log(close / lag_close)
  )

# Indicators
macd_vals <- MACD(df$close, nFast = 12, nSlow = 26, nSig = 9)
df <- df %>% mutate(
  sma_5 = SMA(close, n = 5),
  sma_10 = SMA(close, n = 10),
  rsi_14 = RSI(close, n = 14),
  macd = macd_vals[, "macd"],
  signal = macd_vals[, "signal"],
  volatility_20 = rollapply(log_return, 20, sd, fill = NA, align = "right")
) %>% drop_na()
```

### Train-Test Split
```{r}
split_index <- floor(0.7 * nrow(df))
train <- df[1:split_index, ]
test <- df[(split_index+1):nrow(df), ]
```

### Baseline Model
```{r}
test <- test %>% mutate(pred_baseline = lag_close)
mape_baseline <- mape(test$close, test$pred_baseline)
rmse_baseline <- rmse(test$close, test$pred_baseline)
```

### Train Models
```{r}
formula <- close ~ lag_close + sma_5 + sma_10 + rsi_14 + macd + signal + cpiaucns + unrate + fedfunds

# Linear Regression
lm_model <- lm(formula, data = train)
pred_lm <- predict(lm_model, test)
mape_lm <- mape(test$close, pred_lm)
rmse_lm <- rmse(test$close, pred_lm)

# SVR
svr_model <- svm(formula, data = train)
pred_svr <- predict(svr_model, test)
mape_svr <- mape(test$close, pred_svr)
rmse_svr <- rmse(test$close, pred_svr)

# Random Forest
rf_model <- randomForest(formula, data = train, ntree = 100)
pred_rf <- predict(rf_model, test)
mape_rf <- mape(test$close, pred_rf)
rmse_rf <- rmse(test$close, pred_rf)

# XGBoost
train_matrix <- model.matrix(formula, data = train)[, -1]
test_matrix <- model.matrix(formula, data = test)[, -1]
xgb_model <- xgboost(data = train_matrix, label = train$close, nrounds = 100, objective = "reg:squarederror", verbose = 0)
pred_xgb <- predict(xgb_model, test_matrix)
mape_xgb <- mape(test$close, pred_xgb)
rmse_xgb <- rmse(test$close, pred_xgb)
```

### Directional Accuracy
```{r}
directional_accuracy <- function(actual, predicted) {
  mean(sign(diff(actual)) == sign(diff(predicted)), na.rm = TRUE)
}

acc_rf <- directional_accuracy(test$close, pred_rf)
acc_xgb <- directional_accuracy(test$close, pred_xgb)
```

### Financial Metrics
```{r}
calculate_strategy_metrics <- function(predictions, lag_close, log_return) {
  strategy_return <- ifelse(predictions > lag_close, log_return, 0)
  strategy_cum_return <- exp(cumsum(replace_na(strategy_return, 0)))
  sharpe_ratio <- mean(strategy_return, na.rm = TRUE) / sd(strategy_return, na.rm = TRUE)
  drawdown <- cummax(strategy_cum_return) - strategy_cum_return
  max_drawdown <- max(drawdown / cummax(strategy_cum_return), na.rm = TRUE)
  return(list(sharpe_ratio = sharpe_ratio, max_drawdown = max_drawdown))
}

# Attach predictions to test
test <- test %>% mutate(
  pred_lm = pred_lm,
  pred_svr = pred_svr,
  pred_rf = pred_rf,
  pred_xgb = pred_xgb
)

metrics_lm <- calculate_strategy_metrics(test$pred_lm, test$lag_close, test$log_return)
metrics_svr <- calculate_strategy_metrics(test$pred_svr, test$lag_close, test$log_return)
metrics_rf <- calculate_strategy_metrics(test$pred_rf, test$lag_close, test$log_return)
metrics_xgb <- calculate_strategy_metrics(test$pred_xgb, test$lag_close, test$log_return)
```

# Model Comparison & Selection

### Summary Table
```{r}
results <- tibble(
  Model = c("Baseline", "Linear", "SVR", "RF", "XGBoost"),
  MAPE = c(mape_baseline, mape_lm, mape_svr, mape_rf, mape_xgb),
  RMSE = c(rmse_baseline, rmse_lm, rmse_svr, rmse_rf, rmse_xgb),
  Directional_Accuracy = c(
    directional_accuracy(test$close, test$pred_baseline),
    directional_accuracy(test$close, test$pred_lm),
    directional_accuracy(test$close, test$pred_svr),
    acc_rf,
    acc_xgb
  ),
  Sharpe_Ratio = c(NA, metrics_lm$sharpe_ratio, metrics_svr$sharpe_ratio, metrics_rf$sharpe_ratio, metrics_xgb$sharpe_ratio),
  Max_Drawdown = c(NA, metrics_lm$max_drawdown, metrics_svr$max_drawdown, metrics_rf$max_drawdown, metrics_xgb$max_drawdown)
)
print(results)
```

### Visual Comparison
```{r}
ggplot(results, aes(x = Model, y = MAPE)) +
  geom_col(fill = "steelblue") +
  labs(title = "Model Comparison by MAPE") +
  theme_minimal()
```


```{r}
ggplot(results, aes(x = Model, y = RMSE)) +
  geom_col(fill = "orange") +
  labs(title = "Model Comparison - RMSE", y = "RMSE", x = "Model") +
  theme_minimal()
```



```{r}
ggplot(results %>% drop_na(Directional_Accuracy), aes(x = Model, y = Directional_Accuracy)) +
  geom_col(fill = "darkgreen") +
  labs(title = "Model Comparison - Directional Accuracy", y = "Accuracy", x = "Model") +
  theme_minimal()
```


```{r}
ggplot(results %>% drop_na(Sharpe_Ratio), aes(x = Model, y = Sharpe_Ratio)) +
  geom_col(fill = "purple") +
  labs(title = "Model Comparison - Sharpe Ratio", y = "Sharpe", x = "Model") +
  theme_minimal()
```


```{r}
ggplot(results %>% drop_na(Max_Drawdown), aes(x = Model, y = Max_Drawdown)) +
  geom_col(fill = "red") +
  labs(title = "Model Comparison - Max Drawdown", y = "Drawdown", x = "Model") +
  theme_minimal()
```





### Feature Importance
```{r}
varImpPlot(rf_model)
xgb.plot.importance(xgb.importance(model = xgb_model))
```

### Model Selection Criteria

- MAPE ≤ 5%
- Directional Accuracy ≥ 55%
- Sharpe Ratio ≥ 0.8
- Max Drawdown ≤ 15%
